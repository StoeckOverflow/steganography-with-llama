# Seekers
This module contains the implementation of various seekers for the detection of generative linguistic steganography in newspaper articles.

## DetectGPT

### Basic Idea
The DetectGPT algorithm is a method for identifying text that has been generated by LLMs without the need of training a separate classifier, collecting a dataset of real or generated texts, or explicitly watermarking generated text. Instead, DetectGPT relies on analyzing the curvature of the log probability function of the LLM. It has been found that text generated by an LLM tends to fall into negative curvature regions of this function. By using log probabilities computed by the LLM and random perturbations from another pre-trained language model (like T5), DetectGPT can effectively distinguish between human-written and LLM-generated text.

Source: https://arxiv.org/abs/2301.11305

### Limitations
Since llm-generated text is used for steganography in the newspaper articles, we thought this approach could be a good start and the different log-probabilities could be useful to differentiate between human-written and llm-generated stego text. Unfortunately, the predictions are identical for human-written and llm-generated stego text.
We hypothesize that although the steganography algorithms use llms to generate coherent text, in the algorithm, the choice of the next prompted words is outside the distribution of the llm model and therefore the values of the log probabilities are also affected (as they form a probability chain). As a result, LLM-generated newspaper articles containing steganography are usually incorrectly classified as human-written. We have therefore excluded the Detect-GPT method as a possible seeker method.

## DNA-GPT

### Basic Idea
The Divergent N-Gram Analysis (DNA-GPT) is a training-free strategy for detecting whether a text is machine-generated by large language models (LLMs). The method involves truncating a given text in the middle, using only the first part as input to an LLM, and then regenerating the remaining part. The original and regenerated parts are compared using N-gram analysis (in a black-box approach) or probability divergence (in a white-box approach). This comparison should reveal significant differences between the distributions of machine-generated and human-written text.

Source : https://arxiv.org/abs/2305.17359

### Limitations
LLM-generated texts have a limited vocabulary and often use recurring sentence structures in longer texts, while human-written texts are more complex and have less repetitive sentence structures. Therefore, our assumption was that llm-generated stego text could also have a certain degree of recurring sentence structures also called n-grams. In the paper, n-grams ranging in the range from 5 to 24 were tested. We tested n-grams in the range from 0 to 3 due to the shift caused by the stego algorithm. Unfortunately, in the tested feeds (including the stop words) there were too few and too irregularly considered repetitive sentence structures in the newspaper articels that could have enabled a good classification. Therefore we also excluded the DNA-GPT method as a possible seeker method.