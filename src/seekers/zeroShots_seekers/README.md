# Zero Shot Methods

## DetectGPT

### Basic Idea
DetectGPT is a zero-shot method for identifying LLM-generated text without the need of training a separate classifier, collecting a dataset of real and generated or explicitly watermarked texts. Instead, DetectGPT analyzes the curvature of the log probability function of the input text. The authors demonstrate that LLM-generated texts most likely falls into the negative region of the LLMs log probability function. DetectGPT evaluates the log probabilities of the input text and normalizes them with the mean standard deviation of the log probabilities of version of the input text containing random perturbations from another pretrained LLM. We used Llama 7B as base model and the T5 7B model for generating the random perturbations.

Source: https://arxiv.org/abs/2301.11305

### Limitations

![Example Image](/resources/figures/detectGPT_testrun_01.png)

As our steganography embedded text is also generated by a LLM, we presumed the steganographic text could also fall in the same region as LLM-generated text. Unfortunately the log probability distribution of human-written text and steganographic text generated by the arithmetic hider is nearly identical. Although generative steganography relies on LLMs to generate coherent text, the log-probability function of the steganographic text is determined by the steganographic encoding algorithm and not the LLM itself. This is the reason, we discarded DetectGPT as valuable approach.

## DNA-GPT

### Basic Idea
The Divergent N-Gram Analysis (DNA-GPT) is another zero-shot method for detecting LLM-generated text. The input text first truncated in the two parts X and $Y_0$. X is then prompted into the LLM K times to get 1-K alternative versions of y. $Y_0$ and $Y_1$ to Y_k$ are then compared by using N-Gram Analysis in the black-box approach or probability divergence in the white-box approach. We have chosen the black-box approach, as we assumed to not know the model that is used in the generation of the steganographic text. In the black-box approach we compare the n-gram similarity based on the assumption that human-written Y0 has less overlap with LLM-generated texts $Y_1$ to $Y_k$. Given the function $f(n) = n \log(n)$, with $n_0$ = 0 and N = 3, the BScore is defined as::

$$
BScore(S, \Omega) = \frac{1}{K} \sum_{k=1}^{K} \sum_{n=n_0}^{N} f(n) \cdot \frac{\left| \text{grams}(Y_k, n) \cap \text{grams}(Y_0, n) \right|}{\left| Y_k \right| \text{grams}(Y_0, n)}
$$


LLM-generated texts have a limited vocabulary and often use recurring sentence structures in longer texts, while human-written texts are more complex and have less repetitive sentence structures. Therefore, our assumption was that LLM-generated steganographic text could may have a certain degree of recurring n-grams. As out input texts have a small word range of approximately 100 we tested on a (0,3) n-grame range, whereas in the paper a (5,24) range was used.

Source : https://arxiv.org/abs/2305.17359

### Limitations
Unfortunately, in the generative steganographic texts there are too few and too irregularly considered repetitive sentence structures in the newspaper articles that could have enabled a good classification. As in the DetectGPT method the steganographic encoding algorithm and not the LLM itself determines the words which leads to less recurring n-grams and repetitive structures in the text, which prevents a profound classification. Therefore we also discarded the DNA-GPT method as as valuable approach.